\documentclass[13pt]{article}
\usepackage{amsmath, amsthm, amssymb, graphicx, enumitem, esvect}


% Language setting
% Replace `english' with e.g. `spanish' to change the document language
\usepackage[english]{babel}

% Set page size and margins
% Replace `letterpaper' with `a4paper' for UK/EU standard size
\usepackage[letterpaper,top=2cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}

\title{C\&EE 110}
\date{}

\begin{document}
\maketitle
\tableofcontents

\newpage
\section{Descriptive Statistics}
\subsection{Sample/Population Mean}
Sample Mean:
\[\overline{y} = \frac{\sum_{i = 1}^{n} y_{i}}{n}\]
Popoulation Mean:
\[\mu = \frac{\sum_{i = 1}^{N} y_{i}}{N}\]

\subsection{Sample Variance/Standard Deviation}
Sample Variance:
\[s^{2} = \frac{\sum_{y_{i} - \overline{y}}^{n} y_{i}}{n - 1}\]
\[s = \sqrt{s^{2}} = \sqrt{\frac{\sum_{i = 1}^{n} (y_{i} -
      \overline{y})}{n - 1}}\]

\subsection{Empirical Rule}
For approximately symmetrical (\textit{Gaussian}) distributions:
\begin{enumerate}[label=(\roman*)]
\item $\mu \pm \sigma$: contains $\sim$68\% of the samples
\item $\mu \pm 2\sigma$: contains $\sim$95\% of the samples
\item $\mu \pm 3\sigma$: contains $\sim$99\% of the samples
\end{enumerate}

\subsection{Skew}
\subsubsection{Negative/Left Skew}
Mass of the distribution is concentrated on the right. Consequently,
the \textbf{tail} of the distribution points left. Note that in a negative/left
skew: mean $\leq$ median $\leq$ mode.

\subsubsection{Symmetric/No Skew}
Statistician's wet dream: mean = median = mode.

\subsubsection{Positive/Right Skew}
Mass of the distribution is concentrated on the left. Consequently,
the \textbf{tail} of the distribution points right. Note that in a positive/right
skew: mean $\leq$ median $\leq$ mode.





\section{Probability and Bayes Theorem}
\subsection{Overview}
\subsubsection{Experiment/Aleatory Experiment}
Experiment: Process by which an observation is made \\
Aleatory Experiment: When replicated under the same conditions, the
experiment may not yield the same results; that is, conditions of the
experiment determine the probabilistic behavior of the results.

\subsubsection{Sample Space} Set consisting of all possible outcomes
(samples) of an aleatory experiment. Sample spaces can be:
\begin{itemize}[label=-]
\item continuous or discrete
\item finite, non/enumerable infinity
\end{itemize}

\subsubsection{Event} A subset of the sampling space ($\subseteq$)

\subsection{Set Notation and Boolean Algebra}
\subsubsection{Sub/Sets} A set is a collection of items/elements, each
with a specified characteristic. A set that includes \textbf{all}
items of interest is called the \textbf{universal set} and is denoted
by $\Omega$. Sets can be discrete or continuous. \\ \\
A subset is a set derived from the universal set $\Omega$. Set
relationships can be illustrated via a Venn Diagram. If $A$ is a
subset of $B$ and $B$ is a subset of $\Omega$, we denote that as $A
\subseteq B \subseteq \Omega$.

\subsubsection{Set Operations}
Given sets $A$ and $B$,

\subsubsection*{Intersection ($\cap$)} The intersection of two sets is
defined as $A \cap B := \{x : x \in A \text{ and } x \in B\}$. \\
\textit{\textbf{Note:}} We call two sub/sets $A, B$ \textbf{disjoint
  mutually exclusive} if $A \cap B = \O$

\subsubsection*{Union ($\cup$)} The union of two sets is
defined as $A \cup B := \{x : x \in A \text{ (inclusive) or } x \in B\}$.

\subsubsection*{Complement ($\overline{A}$)} The complement of a set is
defined as $\overline{A} := \{x : x \not\in A\}$

\subsubsection*{Boolean Algebra}
JUST TAKE THE PICS FROM SLIDES


\section{Frequentist Probability}
Based on previous relative frequences, the following conditions must
hold:
\begin{enumerate}[label=(\roman*)]
\item The relative frequence of occurerence of an event must be $\geq
  0$
\item The relative frequency of the whole sample space must be $1$
\item If two events are mutually exclusive, the relative frequency of
  their union is the sum of their respective relative frequencies
\end{enumerate}
Each random event $E$ is associated with a probability $P(E)$ of the
occurrence of the event:
\[P(E) = \frac{N_{E}}{N}\]
where $N_{E}$ is the number of elements in the set $E$ (i.e., the
number of outcomes favorable to the event $E$) and $N$ is the number
of elements in $S$ (i.e., all possible outcomes)

\subsection{Axioms}
Supposed $S$ is a sample space associated with an experiment and $E$
is a random event in $S$. Then,
\begin{enumerate}[label=(\roman*)]
\item $0 \leq P(E) \leq 1$
\item $P(S) = 1$
\item If $\bigcap_{i = 1}^{\infty} E_{i} = \O$, then $P\big(\bigcup_{i =
    1}^{\infty} E_{i}\big) = \sum_{i = 1}^{\infty} P(E_{i})$
\end{enumerate}





\section{Discrete Random Variables}
A random variable $X$ is a numerical representation of every
outcome. They can be discrete or continuous.

\subsection{Probability Mass Function}
Probability Mass Function: Assigns a probability to each possible
domain value of $X$
\[P(X = x_{i}) = p_{i}, \ i = 1, 2, \ldots\]
where $0 \leq P(X = x_{i}) \leq 1$ and $\sum_{i} P(X = x_{i}) = 1$. \\ \\

\subsection{Cumulative Distribution Function}
\[F(X) = P(X \leq x) = \sum_{i : x_{i} \leq x} P(X = x_{i})\]

such that
\begin{enumerate}[label=(\roman*)]
\item $F(x_{1}) \leq F(x_{2}) \ \forall x_{1} \leq x_{2}$
\item $\lim_{x \rightarrow -\infty} F(x) = 0$
\item $\lim_{x \rightarrow +\infty} F(x) = 1$
\end{enumerate}

\subsection{Expectation}
If $X$ is a discrete random variable with a probability distribution
$p(x)$, then the expectation of $X$ is:
\[E(X) = \sum  x \cdot p(x)\]
Composite expectations: $p(x), g(X)$:
\[E\big[g(X)\big] = \sum g(x) \cdot p(x)\]

\subsection{Variance/Standard Deviation}


\subsection{Binomial Distribution}
Has the following properties:
\begin{enumerate}[label=(\roman*)]
\item Binary outcomes
\item Independent trials
\item $n$ number of trials
\item Same probability $p$ per trial
\end{enumerate}
\subsubsection{Mean} \[\mu = n \cdot p\]

\subsubsection{Variance/Standard Deviation}
Variance:
\[\sigma^2 = n \cdot p \cdot (1 - p)\]
or
\[\sigma^2 = n \cdot p \cdot q \text{ where } q = (1 - p)\]
Standard Deviation:
\[\sigma = \sqrt{\sigma^2} = \sqrt{n \cdot p \cdot (1 - p)}\]
or
\[\sigma = \sqrt{\sigma^2} = \sqrt{n \cdot p \cdot q}\]

\subsubsection{Probability}
\[P(X = x) = {n \choose x}p^{x}q^{n - x}\]
or
\[P(X = x) = \frac{n!}{(n - x)!x!} \cdot p^{x}q^{n - x}\]
where $n =$ trials, $p =$ success, $q=$ failure

\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
