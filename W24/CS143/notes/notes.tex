\documentclass{report}
\usepackage{amsmath, amsthm, amssymb, graphicx, enumitem, esvect}
\usepackage[english]{babel}
\usepackage[letterpaper,top=2cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}
\usepackage[most]{tcolorbox}
\usepackage[hidelinks]{hyperref}
\usepackage{graphicx}
\usepackage{nicefrac}
\usepackage{titlesec}
\usepackage{mathtools}

\newenvironment{definition}[1]{\begin{tcolorbox}[title={Definition: #1}]}{\end{tcolorbox}}
\newenvironment{example}{\begin{tcolorbox}[title={Example},colback=green!5!white,colframe=black!75!green]}{\end{tcolorbox}}
\newenvironment{aside}[1]{\begin{tcolorbox}[title={Aside: #1},colback=blue!5!white,colframe=black!75!blue]}{\end{tcolorbox}}


% \newcommand{\refto}[2]{\textbf{\ref{#1:#2} \nameref{#1:#2}}}
\renewcommand{\bf}[1]{\textbf{{#1}}}
\renewcommand{\tt}[1]{\texttt{{#1}}}
\renewcommand{\it}[1]{\textit{{#1}}}
\newcommand{\ib}[1]{\textit{\textbf{{#1}}}}
\newcommand{\R}{\mathbb{R}}

\setlength{\parindent}{0pt}
\titleformat{\chapter}[display]{\normalfont\huge\bfseries}{\vspace{-100pt}}{20pt}{\Huge}

\title{CS 143}
\author{Warren Kim}
\date{}

\begin{document}
\maketitle

\tableofcontents
\newpage

\chapter{Overview}
\section{Purpose of a Database}
We will be studying (mostly) Relational DataBase Management Systems (RDBMS).
\begin{definition}{Database}
    A \bf{database} abstracts how data is stored, maintained, and processed. It is a system that uses
    advanced data structures to store and index data.
\end{definition}
A database abstracts away the data integrity and file management aspect of CRUD operations. Moreover,
a database provides us with a single location for all of the data, even if the database itself is
distributed.


\section{Abstraction Layers}
There are three layers of abstraction: physical, logical, and view. 
\begin{definition}{Physical Abstraction}
    The \bf{physical abstraction} defines the data and its relationships to other data within the 
    database.
\end{definition}
\begin{definition}{Logical Abstraction}
    The \bf{logical abstraction} deals with how we interface with the database.
\end{definition}
\begin{definition}{View Abstraction}
    The \bf{view abstraction} refers to specific use cases and filters the data from the logical
    abstraction.
\end{definition}
We start by learning the logical abstraction.


\section{Instances and Schema}
\begin{definition}{Schema and Instance}
    A \bf{schema}\footnote{Note: schema can also refer to a relation (table).} is the overall design 
    of a database. It defines the structure of the data as well as how it is organized. \vspace{10pt}

    An \bf{instance} of a database is the actual set of data stored in the database at a particular 
    moment in time. 
\end{definition}


\section{Data Models}
Data models define how we design databases and interact with data. We want to answer the following:
\begin{enumerate}[label=$\to$]
    \item How do we define data?
    \item How do we encode relationships among data?
    \item How do we impose constraints on data?
\end{enumerate}
Data models are either an Implementation model or a Design mechanism. Implementation models build 
databases from the ground up while design mechanisms are implemented as features in a database. We 
discuss five major types (an several niche ones).

\subsection{Relational}
In a relational model, all data is stored as a \ib{relation}\footnote{Note: tables are an 
implementation of relations.}. Rows represent individual $n$-tuple units (\ib{records}). Columns 
represent (typed) \ib{attributes} common to all records in the relations.

\subsection{Entity-Relationship (ER)}
An entity-relationship model uses a collection of basic objects (\ib{entities}) and define 
\ib{relationships} among them.

\subsection{Object-Oriented}
The object-oriented model is similar to OOP with encapsulation, methods, adn object identity. It
was originally an implementation model but is now a design mechanism.

\subsection{Document (Semi-Structured)}
A document model stores records as \ib{documents}, which do \ib{not} have an enforced schema. This 
allows for more versatility in the type of data stored in the database.

\subsection{Network/Hierarchical/Graphical}
A graph model is analogous to how we think. Records are stored as \ib{nodes} and relationships 
between records as \ib{edges}.

\subsection{Vector}
A vector model stores records as \ib{vectors} in $\mathbb{R}^{n}$, and are stored in a way that 
enables efficient retrieval and comparison (e.g. nearest neighbor[s]).

\subsection{Key-Value}
A key-value model stores data as a key-value pair (typically using a hash function). In this model,
data typically lives in RAM as opposed to disk.


\section{Database Languages}
There are two main semantic systems when working with databases:
\begin{enumerate}[label=$\to$]
    \item Data Manipulation Language (DML)
    \item Data Definition Language (DDL)
\end{enumerate}
Note that a relational model typically uses SQL for both DDL and DML.

\subsection{Data Manipulation Language}
DML's can either be procedural or declarative.
\begin{definition}{Query}
    A \ib{query} is a written expression to retrieve or manipulate data.
\end{definition}
\begin{aside}{A Note on SQL}
    SQL is a declarative language, and as such, it is hard to perform sequential or 
    nontrivial\footnote{Nontrivial: Any computation where we have to specify \it{how} to perform
    the computation.} computations in SQL. To remedy this, a common option is to write an \ib{ETL job}
    in another language (pick one). We \bf{E}xtract the data from the database (using a connection
    driver), \bf{T}ransform the data using another lanuage (pick one!), and \bf{L}oad the data
    into a new table using the same driver. We can schedule these jobs using something like \tt{cron}.
\end{aside}

\subsection{Data Definition Language}
DDL's specify a schema: a collection of attribute names and data types, consistency constraints, and
optionally storage structure and access methods. There are four types of consistency constraints:
\begin{enumerate}[label=$\to$]
    \item Domain constraints define the domain of an attribute (e.g. \tt{tinyint}, \tt{enum}, etc.).
    \item Assertions are business rules that must hold true (e.g. an enforced prerequisite for a 
        class must be present in your transcript before you can add a class to your study list).
    \item Authorization determines who can do what (e.g. full CRUD, read-only, etc.).
    \item Referential integrity ensures that links from one table to another must be defined (Suppose
        we have two relations $R, R'$. If there is a link $f : R \to R'$, then $f$ is surjective).
\end{enumerate}


\section{Data Storage and Querying}
\begin{definition}{Storage Manager}
    A \ib{storage manager} that abstracts away how the data is laid out on disk.
\end{definition}
A storage manager is helpful because reading data from disk to RAM is \it{slow}, and the storage
manager handles swapping\footnote{Swapping: Virtual memory in CS111!} and makes retrieval efficient.

\begin{definition}{Query Manager}
    A \ib{query manager} takes the DML statements and organize them into a 
    \it{query plan}\footnote{Note: The query plan dictates the performance of a query.} that 
    ``compiles'' a query (using relational algebra) and executes the instruction(s).
\end{definition}


\section{Defining a Schema}
A schema can be written as \tt{relation(\underline{attribute$_{\tt{1}}$}, \tt{$\ldots$}, 
attribute$_{\tt{n}}$}) where underlined attributes represent the primary key.





\chapter{Keys}
\begin{aside}{A Note on Context and Instance}
    Based on \bf{context} means that the given data is a subset of the complete dataset.
    \newline
    Based on \bf{instance} means that we treat the given data as the complete dataset.
\end{aside}


\section{Superkey}
\begin{definition}{Superkey}
    A \bf{superkey} is a set of one or more attributes that uniquely identifies a record (tuple) and 
    distinguishes it from all other records in the relation.\vspace{10pt}

    Formally, let $R$ be a relation with a set $S = \{a_1, a_2, \ldots, a_n : a 
    \text{ is an attribute of } R\}$. A \bf{superkey} is a subset $s \subseteq S$ such that $s$ 
    uniquely identifies each $n$-tuple in $R$.
\end{definition}
The superkey $s = S = \{a_1, a_2, \ldots, a_n\} = \bigcup^{n}_{i = 1} \{a_i\}$ is called the 
\ib{trivial superkey}. Additionally, $\emptyset$ is not a superkey. Further note that for every 
relation $R$, there exists at most $2^n - 1$ superkeys where $n$ is the number of 
attributes.


\section{Candidate Key}
\begin{definition}{Candidate Key}
    A \bf{candidate key} is a superkey such that no subset of the candidate key is a superkey; i.e.
    it is the minimal superkey. \vspace{10pt}

    Formally, let $R$ be a relation with a set $S = \{a_1, a_2, \ldots, a_n : a 
    \text{ is an attribute of } R\}$. A \bf{candidate key} is a superkey $s \subseteq S$ such that
    for every propery subset $t \subsetneq s$, $t$ is not a superkey.
\end{definition}
Candidate keys may vary in length, and the attributes of a candiate key may be \tt{NULL} as long as
it uniquely identifies an $n$-tuple in the relation.


\section{Primary Key}
\begin{definition}{Primary Key and Composite Key}
    A \bf{primary key} is a candidate key (chosen by the database designer) to enforce uniqueness
    for a particular use case.
\end{definition}
The primary key is typically chosen to be the minimal candidate key for simplicity. The attributes
of a primary key may not be \tt{NULL}. 

\section{Foreign Key}
\begin{definition}{Foreign Key}
    A \bf{foreign key} is a set of attributes that links tuples of two relations.\vspace{10pt}

    Formally, let $R, R'$ be relations with sets $S = \{a_1, a_2, \ldots, a_n : a 
        \text{ is an attribute of } R\}, S' = \{a'_1, a'_2, \ldots, a'_n : a' \text{ is an attribute of }
    R'\}$. A \bf{foreign key} is a key $s \subseteq S$ of $R$ that maps to the primary key 
    $p \subseteq S'$ of $R'$.
\end{definition}
Foreign keys are used to enforce referential integrity constraints; i.e. foreign keys in a 
relation $R$ are used to protect data in $R$ from being orphaned and/or inconsistent. Given two
relations $R, R'$ related via a foreign key, $R'$ is said to be the \it{referring} relation and 
$R$ the \it{referred} relation.

Let two relations $R, S$ be related via a foreign key, where $S$ is the \it{referring} relation
and $R$ is the \it{referred} relation. Suppose we want to remove an $n$-tuple $r \in R$. Then there
are two cases:
\begin{enumerate}[label=\textit{Case \arabic*}]
    \item If there is no $s \in S$ such that $s \mapsto r$, we simply remove $r$.
    \item If there is at least one $s \in S$ such that $s \mapsto r$, we can either throw an error
        to prevent the deletion of $r$ or \it{cascade}\footnote{Cascade: Delete $r$ and all 
        $s \in S$ that refer to $r$.} the delete.
\end{enumerate}





\chapter{Relational Algebra}

\section{Selection}
\begin{definition}{Selection}
    \bf{Selection} retrieves a subset of tuples from a \it{single} relation $R$ that satisfies some
    predicate $\psi$ and returns a new relation $R' \subseteq R$, and is defined by
    \[\sigma_{\psi}(R) = R' = \{ t \in R : \psi(t) \}\]
    where $\psi$ is a boolean predicate on attributes and values with respect to a unary or binary 
    operator\footnote{We may use the following operators: $\{=, \neq, <, >, \leq, \geq, \lnot \}$.}
\end{definition}
We can build complex predicates using conjunction $\land$ (and) or disjunction $\lor$ (or). 
\begin{center}\bf{Note: that selection $\sigma$ is the most analogous to \tt{WHERE} in SQL.} \end{center}
Below are a list of examples of selection, assuming all attributes and relations are well-defined:
\begin{enumerate}[label=\textit{(\roman*)}]
    \item $\sigma_{(\tt{dislikes} < \tt{likes})}(\tt{youtube\_video})$
    \item $\sigma_{(\tt{cat\_id} = 17)}(\tt{youtube\_video})$
    \item $\sigma_{([\tt{dislikes} < \tt{likes}] \land [\tt{views} > 1000000] \land [\tt{cat\_id=24}])}(\tt{youtube\_video})$
    \item $\sigma_{(\tt{dislikes} < \tt{likes})}(\sigma_{(\tt{views} > 1000000)}(\sigma_{(\tt{cat\_id} = 24)}(\tt{youtube\_videos})))$
\end{enumerate}
Note that \it{(iii)} and \it{(iv)} are equivalent.

\section{Projection}
\begin{definition}{Projection}
    \bf{Projection} extracts attributes from a set of tuples and removes duplicates. Given a 
    relation $R$, $n$-tuple $t$, and a set of attributes $a_1, \cdots, a_n$,
    \[\Pi_{a_1, \cdots, a_n}(R) = \{ t[a_1, \cdots, a_n] : t \in R \}\]
    Projection is usually the last (outermost) operation done on a relation.
\end{definition}
\begin{aside}{Projection?}
    We call it a projection because we are collapsing an $n$-tuple down to an $(n - k)$-tuple. That
    is, we take the $n$-tuples in a relation $R_n$ and collapse them into a set of $(n-k)$-tuples 
    in a new relation $R'_{n - k}$. \footnotetext{Here, $R_n$ is a relation with $n$ attributes.}
\end{aside}
Projections can be generalized to ``create'' new attributes or rename attributes using the $\to$
notation.
\begin{example}
    We can apply arbitrary expressions to existing attributes (and create another one) by doing
    $\Pi_{\tt{likes} / (\tt{likes} + \tt{dislikes}) \to \tt{interactions}}(R)$
    or rename attributes by doing
    $\Pi_{\tt{likes} \to \tt{thumbs\_up}}(R)$
\end{example}
\begin{example}
    Consider the following relation $R$ with $\Pi_{A, B}(R)$:
    \begin{center}
        \begin{tabular}{c|c|c}
            A & B & C \\
            \hline
            $\alpha$ & $\beta$ & $\delta$ \\
            $\alpha$ & $\beta$ & $\gamma$ \\
            $\alpha$ & $\beta$ & $\lambda$
        \end{tabular}
        $\overset{\it{Extract} A, B}{\longrightarrow}$
        \begin{tabular}{c|c}
            A & B \\
            \hline
            $\alpha$ & $\beta$ \\
            $\alpha$ & $\beta$ \\
            $\alpha$ & $\beta$
        \end{tabular}
        $\overset{\Pi_{A, B} (R)}{\longrightarrow}$
        \begin{tabular}{c|c}
            A & B \\
            \hline
            $\alpha$ & $\beta$
        \end{tabular}
    \end{center}
\end{example}
\begin{center}\bf{Note: that projection $\Pi$ is the most analogous to \tt{SELECT DISTINCT} in SQL.} \end{center}


\section{Cartesian Product}
\begin{definition}{Cartesian Product}
    A \bf{Cartesian product} forms all possible pairs of tuples. Given relations $R, S$,
    \[R \times S = \{ (r, s) : r \in R \land s \in S \}\]
\end{definition}
\begin{example}
    Suppose we have two relations $R, S$ defined below:
    \begin{center}
        $R :=$
        \begin{tabular}{c|c}
            A & B \\
            \hline
            $\alpha$ & $\beta$ \\
            $\alpha$ & $\gamma$
        \end{tabular}
        , $S :=$
        \begin{tabular}{c|c}
            A & B \\
            \hline
            $\alpha$ & $\gamma$ \\
            $\Delta$ & $\eta$
        \end{tabular}
    \end{center}
    Then, 
    \begin{center}
        $R \times S =$
        \begin{tabular}{c|c|c|c}
            A & B & C & D \\
            \hline
            $\alpha$ & $\beta$ & $\alpha$ & $\gamma$ \\
            $\beta$ & $\gamma$ & $\Delta$ & $\eta$ \\
            $\Delta$ & $\eta$ & $\alpha$ & $\gamma$ \\
            $\Delta$ & $\eta$ & $\beta$ & $\gamma$ \\
        \end{tabular}
    \end{center}
\end{example}
Cartesian products are \it{very} expensive since they require a lot of compute power, ram, and disk
space. 

\section{Aggregation}
\begin{definition}{Aggregation}
    The aggregation operator ($\gamma$ or $\mathcal{G}$) is a function on groups of tuples in a relation
    to summarize them. Common ones include: \tt{SUM}, \tt{AVG}, \tt{MIN}, \tt{MAX}, \tt{COUNT}, etc.
    Given a relation $R$,
    \[
        \prescript{}{\it{A}}{\gamma}_{F}(R) = \prescript{}{\it{A}}{\mathcal{G}}_{F}(R)
    \]
    where $A := \{ \text{attributes to group by} \}, F := \{ \text{functions to apply} \}$
\end{definition}

\section{Rename}
\begin{definition}{Rename}
    The rename operator ($\rho$) renames relations or attributes. Given a relation with name $R$,
    renaming a relation looks like $\rho_{R'}(R)$, where $R'$ is the new name. Renaming an attribute
    in $R$ looks like $\rho_{a'/a}(R)$, where $a'$ is the new name. \vspace{10pt}
    
    \bf{Note:} We must rename one of the $R$'s when doing $R \times R$. That is, we must have
    $\rho_{R'}(R) \times R$ or $R \times \rho_{R'}(R)$.
\end{definition}

\section{Set Operations}
\begin{definition}{Set Operations (Union, Intersection, Set Difference)}
    Let $R, S$ be two sets of tuples. Then, union is defined to be
    \[R \cup S = \{ r_1, \cdots, r_{|R|}, s_1, \cdots s_{|S|} : r_i \in R \lor s_j \in S\}\]
    intersection is defined as
    \[R \cap S = \{ t : t \in R \land t \in S\}\]
    and set difference is defined as
    \[R - S = R \setminus S = \{ t : t \in R \land t \notin S\}\]
\end{definition}

\section{Order of Precedence}
The order of precedence from highest to lowest is as follows:
\[(\sigma, \Pi, \rho), (\times, \bowtie), \cap, (\cup, -)\]





\chapter{Joins}
\begin{definition}{Join}
    A \bf{join} merges tuples from two relations $R, S$ based on some contextually related
    attribute(s) in both relations. The resulting relation contains tuples of the form $(r, s)$
    where $r \in R, s \in S$. \vspace{12pt}

    A \bf{join key} is the set of attribute(s) that are used to join $R$ and $S$. Note that a join
    key is \ib{completely unrelated} to do with uniqueness.
\end{definition}
There are two types of joins: natural and theta.


\section{Natural Join}
\begin{definition}{Natural Join}
    A \bf{natural join} $\bowtie$ is a join where the join key is determined by the RDBMS. The
    simplest natural join is defined using the cartesian product:
    \[
        R \bowtie S 
        = \Pi_{R \cup S} \left( \sigma_{R.k = S.k} (R \times S) \right) 
        = \left\{ (r, s) : r \in R \land s \in S \land (r[k] = s[k]) \right\}
    \]
    The natural join is also characterized as an \it{equijoin}.
\end{definition}

\subsubsection{Edge Cases}
\begin{enumerate}
    \item If we have two relations $R, S$ that have no common attributes ($k = \emptyset$), then
        \[
            R \bowtie S 
            = \left\{ (r, s) : r \in R \land s \in S \land (r[k] = s[k]) \right\} 
            = R \times S
        \]
        because the empty set is unique.
    \item If we have two relations $R, S$ that have common attributes but no matches, then
        \[
            R \bowtie S 
            = \left\{ (r, s) : r \in R \land s \in S \land (r[k] = s[k]) \right\} 
            = \emptyset
        \]
        because $r[k] = s[k]$ is always false.
\end{enumerate}


\section{Theta Join}
\begin{definition}{Theta Join}
    A \bf{theta join} $\bowtie_{\theta}$ is a join where the join key and condition are specified.
    Mathematically,
    \[
        R \bowtie_{\theta} S 
        = \sigma_{\theta} (R_1 \times R_2)
        = \left\{ (r, s) : r \in R \land s \in S \land \theta((r, s)) \right\}
    \]
    where $\theta$ is the join condition.
\end{definition}
\ib{Note:} For any join, if there is a name clash in either the relation or attribute(s), we must
alias them.
\begin{example}
    Suppose we have two relations $R, S$ defined below:
    \begin{center}
        $R :=$
        \begin{tabular}{c|c}
            A & B \\
            \hline
            $\alpha$ & $\beta$ \\
            $\beta$ & $\beta$
        \end{tabular}
        , $S :=$
        \begin{tabular}{c|c}
            A & B \\
            \hline
            $\beta$ & $\alpha$ \\
            $\alpha$ & $\gamma$
        \end{tabular}
    \end{center}
    Define $\theta := R.A = S.A$. Then,
    \begin{center}
        $R \bowtie_{\theta} S = R \bowtie_{R.A = S.A} S =$
        \begin{tabular}{c|c|c|c}
            A & B & C & D \\
            \hline
            $\alpha$ & $\beta$ & $\alpha$ & $\gamma$ \\
            $\beta$ & $\beta$ & $\beta$ & $\alpha$ \\
        \end{tabular}
    \end{center}
\end{example}


\section{Inner Joins}
\begin{definition}{Theta Join}
    An \bf{inner join} between two relations $R, S$ is a theta join that omits elements that do not
    satisfy the join condition $\theta$.
\end{definition}


\chapter{PostgreSQL Data Types}
The ANSI SQL standard defines the following data types:
\begin{enumerate}[label=\textit{(\roman*)}]
    \item numeric
    \item string/text
    \item binary
    \item dates and times
\end{enumerate}

\begin{aside}{Promoted}
    It is always good practice to only promote types to increaese precision, and never demote.
\end{aside}


\section{Numbers}
Numeric data types have the following forms:
\begin{itemize}[label=$\to$]
    \item \tt{int(eger)} (4 bytes)
    \item \tt{smallint} (2 bytes)
    \item \tt{bigint} (8 bytes)
    \item \tt{decimal($n$, $d$)}, where $n$ is the number of digits and $p$ is the number of digits
        that appear after the decimal point. \tt{numeric/decimal} is slow.
    \item \tt{real}, \tt{double precision}
    \item \tt{float($n$)}, where $n$ is the precision.
    \item \tt{NaN} is specified with quotes, and \tt{NaN $==$ NaN} is true and \tt{NaN > x} for all
        \tt{x $\neq$ NaN}. Further, operations on \tt{NaN} return \tt{NaN}.
    \item \tt{Infinity} must be quoted.
\end{itemize}


\section{Strings}
String data types have the following forms:
\begin{enumerate}[label=$\to$]
    \item char($n$) is a fixed-length character array of length $n$.
    \item varchar($n$) is a variable-length character array of length $\leq n$.
\end{enumerate}


\section{Binary Data and Booleans}
\subsection{Binary Data}
\tt{bytea} acceps either hex or escape format.
\subsection{Boolean}
The following are valid: 
\begin{itemize}[label=$\to$]
    \item \tt{TRUE}, \tt{'t'}, \tt{'true'}, \tt{'y'}, \tt{'yes'}, \tt{'on'}, \tt{'1'}
    \item \tt{FALSE}, \tt{'f'}, \tt{'false'}, \tt{'n'}, \tt{'no'}, \tt{'off'}, \tt{'0'}
\end{itemize}




\section{Date/Time}
String data types have the following forms:
\begin{enumerate}[label=$\to$]
    \item date (YYYY-MM-DD)
    \item time (HH:MM:SS)
    \item timestamp (YY-MM-DD)
\end{enumerate}

\newpage
\section{02/12/24}

\subsection{From RDBS To Other Systems}
We'll come back to RDBMS in the context of indexing, transactions, and join algorithms. PostgreSQL
and other RDBMS are called OLTP systems: OnLine Transaction Processing. They are designed for
frequent and \bf{random} interactive use. They are typically used in production\footnote{Production:
power and app or a business. For example, a POS system.}. 

\bf{OLTP}
\begin{enumerate}
    \item Good for simple queries (e.g. \tt{SELECT}, basic joins)
    \item Typically used for quick reads/writes that follow no real pattern.
    \item Based on \it{transactions} or individual events, and these events are stored as rows in
        RDBMS.
    \item Strives to minimize redundnacy and requires joins to exploit relationships in data; i.e.
        normalization.
    \item Designed for production use.
    \item Abstracts data as a 2D representation (rows/columns) called a table.
\end{enumerate}

\subsection{OLAP and Data Warehousing}
OnLine Analytical Processing is \bf{not} meant to be accessed in production. The data is meant to be
used by internal users. OLAP is optimized for reads with low latency. Writes are a little slower.
Typically, other automated systems write into an OLAP; e.g. ETL jobs, piping, etc.
We typically do batch writes and do \it{ad hoc} writing.
\vspace{1em}

\bf{Note:} OLAP/DW are completely different systems from RDBMS/OLTP. But they both use SQL. The
difference is how data is stored and how operations are optimized.

\subsubsection{OLAP}
OLAP is the concept, and Data Warehouses are an implementation of them. Pure OLAP systems aren't
used very often anymore, but many of the concepts are used today in relational databases or data
warehouses. 

We work with \bf{cubes} in OLAP. But, flattened, it still looks like a table. e.g.
\begin{center}
\begin{tabular}{c|c|c|c}
    location & product & shipping & revenue \\
    \hline
    USW & Android Tablet & 2017 & \$5M
\end{tabular}
\end{center}

OLAP and DW are used for batch processing, and not for production systems. They are optimized for
low latency reads of aggregated or precomputed data. Typically, we have a lot of redundancy and
denormalized tables. Some use cases include:
\begin{enumerate}
    \item Reporting (Ledgering)
    \item Dashboarding
\end{enumerate}
We typically write ad hoc into the system using something like an ETL job during a low usage period
(e.g. overnight).
\begin{center}
    DB $\overset{extract}{\longrightarrow}$ Transform $\overset{load}{\longrightarrow}$ Data Warehouse.
\end{center}

\subsubsection{ETL Job}
An ETL job has three steps:
\begin{enumerate}
    \item \bf{Extract:} Pull data form source, usually an RDBMS.
    \item \bf{Transform:} Perform transformation on data.
    \item \bf{Load:} Write the raw data into the data warehouse. Udner OLAP, aggregates or
        denormalized tables will be computed.
\end{enumerate}
This ETL job is costly to the production database. We may lose some data if inserts/updates are
being processed during the transfer. Since we typically work with a lot of data, and we are storing
aggregates, this is \it{usually} okay.

\paragraph{Addressing Performance:}
To improve performance on the RDBMS, we can 

\begin{enumerate}
    \item Have a replica database, and run an ETL job against the replica.
    \item Dual write: on each write, write to the production DB as well as to the replica.
\end{enumerate}

\begin{align*}
    App \longrightarrow Multiplexer^* &\longrightarrow production \ DB \\
                                      &\longrightarrow replica \overset{E}{\to} T \to
                                      \overset{L}{\to} DW
\end{align*}
$^*$Multiplexer: Could be a load-balancer, message queue, etc.
\vspace{1em}

If we have $n$ grouping columns. we have $ \sum_{k = 0}^n \binom{n}{k} = 2^n $ dimensions.
\vspace{1em}

In addition to aggregates, data warehouses can also store ``exploded'' (denormalized) tables for
fast reads. This join can be computed as the data is inserted, and then quickly retrieved by the
user without waiting. The jooin condition can be pre-specified in the schema.


\subsubsection{OLAP v. OLTP}
\begin{itemize}[label=$\to$]
    \item OLAP cubes are computationally expensive.
    \item REads of exploded tables are \it{fast}.
    \item Data is likely to be out of date.
    \item Typically append-only: no modifying/deleting.
    \item Read-only to internal users.
\end{itemize}

\subsubsection{OLAP Operations}
\begin{enumerate}
    \item slice
    \item dice
    \item rollup
    \item drill down
    \item pivot
\end{enumerate}

\paragraph{Slice:} A slice selects one predominant dimension $n$ from a cube and returns a new 
sub-cube, producing a rectangular representation of the data contianing $n$. In SQL, we slicy by
\tt{WHERE condition}.

\paragraph{Dice} A dice selects multiple dimentions $n$ from a cube and returns a new 
sub-cube, producing a rectangular representation of the data contianing $n$. In SQL, we slice by
doing \tt{WHERE condition AND/OR ...}

\bf{Note:} The distinction between slice and dice is usually only in theory. We usually slice.


\paragraph{Rollup} A rollup computes aggregates across all levels of a hierarchical attribute.
For example, $days \subseteq months \subseteq years \subseteq \cdots$. In SQL,
\tt{ROLLUP(A1, ..., An)} where $A_n \subseteq \cdots \subseteq A_1$. Also,
\tt{CUBE(A1, ..., An)} computes aggregates for all subsets of $A_1, \cdots, A_n$.


\end{document}
