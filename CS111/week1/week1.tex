\documentclass{article}
\usepackage{amsmath, amsthm, amssymb, graphicx, enumitem, esvect}
\usepackage[english]{babel}
\usepackage[letterpaper,top=2cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}
\usepackage{tcolorbox}

\newcommand{\definitionBegin}[1]{\begin{tcolorbox}[title={#1}]}
  \newcommand{\definitionEnd}{\end{tcolorbox}}

\newcommand{\exampleBegin}[1]{\begin{tcolorbox}[colback=blue!5!white,colframe=black!75!blue,title={#1}]}
  \newcommand{\exampleEnd}{\end{tcolorbox}}

\newcommand{\abstractionBegin}[1]{\begin{tcolorbox}[colback=violet!5!white,colframe=violet,title={#1}]}
  \newcommand{\abstractionEnd}{\end{tcolorbox}}


\title{CS 111}
\author{Warren Kim}

\begin{document}
\maketitle

\tableofcontents
\newpage

\section{Preface}
% \begin{tcolorbox}[colback=black!5!white,colframe=black!75!black,title=\textit{Operating Systems: Three Easy Pieces}]
%   Text in these boxes will indicate that further details can be found in the textbook
%   (\textit{Operating Systems: Three Easy Pieces} by Arpaci-Dusseau)
% \end{tcolorbox}

\definitionBegin{Definitions}{
  Any definitions will be appear in a grey box like this one. There may be more than one definition
  per box if the topics are dependent on each other or are closely related.}
\definitionEnd

\exampleBegin{Examples}{
  Any examples will be appear in a blue box like this one. Examples will typically showcase a scenario
  that emphasizes the importance of a particular topic.}
\exampleEnd

\abstractionBegin{Abstractions}{
  Layers of abstractions will appear in a violet box like this one. The key point of this box is to
  actively reinforce the concept of abstraction (and recognize how important it is in computer science!).}
\abstractionEnd



\newpage
\section{Preface: Introduction to Abstraction}
\begin{tcolorbox}[title=Definition: Abstraction]
  \textbf{Abstraction} is the concept of providing a (relatively) simple interface to higher level
  programs, hiding unnecessary complexity.
\end{tcolorbox}

The OS implements these abstract resources using physical resources, and thus is the source of one
of the main dilemmas of OS design: What should you abstract?

\begin{tcolorbox}[colback=blue!5!white,colframe=black!75!blue,title=Example: Network Neverland]
  Network cards consist of intricate technical details and specifications, but most users are not
  concerned with those details. As a result, the operating system abstracts the technical aspects of a
  specific network card, such as the process of sending a message, for higher-level programs. Instead
  of manually performing each step to send a message using a particular network card, users can simply
  call the OS's \texttt{send()}\footnote{The actual function name may vary.} function and let the
  operating system handle the complex operations. 
\end{tcolorbox}


\subsection{Why Abstract?}
Abstraction is utilized to simplify code development and comprehension for programmers and
users. Furthermore, it naturally fosters a highly modular codebase as each abstraction introduces an
additional layer of modularity. Moreover, by concealing complexity at each layer of abstraction, it
encourages programmers to concentrate on the essential functionality of a component. 


\subsubsection{Corollary: Generalizing Abstractions}
Due to the variability of a machine's hardware and software, we can abstract the common
functionality of each and make different types appear the same. This way, applications only need to
interface with a common set of libraries. 

\begin{tcolorbox}[colback=blue!5!white,colframe=black!75!blue,title=Example: Printing Press]
  The portable document format (PDF) for printers abstracts away the individual implementation of a
  printer and provides a common format that all printers can recognize and print.
\end{tcolorbox}





\section{Overview}
This section defines what an operating system is as well as gives motivating reasons as to why we
should be studying them. 


\subsection{What is an Operating System?}
\begin{tcolorbox}[title=Definition: Operating System]
  An \textbf{operating system (OS)} is system software that acts as an intermediary between hardware and
  higher level applications (e.g. higher level system software, user processes), acting as an
  intermediary between the two. It manages hardware and software resources and provides common
  services for user programs. 
\end{tcolorbox}

\begin{tcolorbox}[colback=violet!5!white,colframe=violet,title=Abstraction: The Operating System] 
  The operating system plays a crucial role in managing hardware resources for programs, ensuring
  controlled sharing, privacy, and overseeing their execution. Moreover, it provides a layer of
  abstraction that enhances software portability. 
\end{tcolorbox}


\subsection{Why Study Them?}
We study operating systems because we rely on the \textit{\textbf{services}} they offer.

\begin{tcolorbox}[title=Definition: Services]
  In the context of operating systems, \textbf{services} are functionality that is provided
  for by the operating system. They can be accessed via the operating system's API in the form of
  system calls. 
\end{tcolorbox}

Moreover, a lot of hard problems that we run into at the application layer have (probably) already
been solved in the context of operating systems !

\begin{tcolorbox}[colback=blue!5!white,colframe=black!75!blue,title=Example: Difficult Downloads]
  Suppose you are developing a web browser and implementing a \textit{download} feature. While
  downloading things one by one works fine, what if you need to download multiple items from different
  sites simultaneously? Thinking abstractly, we can see that this is a problem of coordinating
  concurrent activities, and fortunately, this problem has already been solved in the context of
  operating systems! Since you have already learned how to tackle this issue in operating systems, now
  you can apply the same solution to your \textit{download} problem!
\end{tcolorbox}


\subsection{Key Topics (OS Wisdom)}
When thinking of how to solve complex problems, these are some things you should take into
consideration (to hopefully make your life a lot easier).


\subsubsection*{Objects and Operations}
Think of a service as an object with a set of well-defined operations. Moreover, thinking of the
underlying data structure(s) of an object may be useful in many situations.  


\subsubsection*{Interface v. Implementation}
\begin{tcolorbox}[title=Definition: Interface and Implementation]
  An \textbf{interface} defines the collection of functionalities offered by your software. It
  specifies the method names, signatures, and the \textit{purpose} of each component. 
  \tcblower
  An \textbf{implementation} refers to the actual code that provides the functionality described by
  the interface. It specifies \textit{how} the interface's operations are executed and realized in practice. 
\end{tcolorbox}
We separate the two components to improve modularity and create robust, well-structured code. It
allows for different compliant implementations (as long as they adhere to the agreed-upon interface
specifications). This provides immense flexibility at the implementation level!

\begin{tcolorbox}[colback=blue!5!white,colframe=black!75!blue,title=Example: Sort Swapping]
  Assume you are writing a library that contains a collection of common algorithms, one of them
  being \texttt{sort()}. Being the genius that you are, your implementation is as follows: Randomly
  reorder the elements until they're sorted. By some miracle, your library garners a lot of
  attention, but users are complaining that \texttt{sort()} takes too long. Not knowing what's wrong
  with your implementation, you take DSA\footnote[1]{DSA: Data Structures and Algorithms} 
  and learn that you've got shit for brains. You want to rewrite \texttt{sort()} but are worried
  that it might break the interface. However, you remember that interface $\neq$ implementation, so
  you rewrite \texttt{sort()} (using something like merge sort) pushing this new implementation
  into production, and bragging about how \texttt{sort()} now runs in O($n \log n$) time. 
\end{tcolorbox}

\subsubsection*{Encapsulation}
We want to abstract away complexity (when appropriate) into an interface for ease of use.

\subsubsection*{Policy v. Mechanism}
\begin{tcolorbox}[title=Definition: Policy and Mechanism]
  A \textbf{policy} is a high-level rule or guideline that governs the \textit{behavior} of a
  system.
  \tcblower
  A \textbf{mechanism} is the implementation that is used to \textit{enforce} the policy.
\end{tcolorbox}
It is important to note that keeping policy and mechanism independent of one another is crucial. By
separating policies from the underlying mechanisms, it becomes easier to change or modify policies
without affecting the core functionality or technical implementation. This approach provides the
ability to update policies independently from the underlying mechanisms, promoting modifiability,
maintainability, and customization when designing software.


\subsection{Why is the OS Special?}
\begin{tcolorbox}[title=Definition: Standard and Privileged Instruction Set]
  The \textbf{standard instruction set} is the set of hardware instructions that can be executed by anybody.
  \tcblower
  The \textbf{privilaged instruction set} is the set of hardware instructions only the kernel can
  execute. When an application wants to execute a privilaged instruction, it must ask the kernel to
  execute it for them.
\end{tcolorbox}

The OS is special for a number of reasons. Mainly, it has \textit{complete} access to the privileged
instruction set, \textit{all} of memory and I/O, and mediates applications' access to
hardware. This implies that the OS is \textit{trusted} to always act in good faith. Thus, the OS
stays up and running as long as the machine is still powered on (theoretically), and if the OS crashes,
you're fucked lol.


\subsection{Miscellaneous}
Below are a list of miscellaneous topics.
\subsubsection{Definitions}
\begin{tcolorbox}[title=Definition: Instruction Set Architectures]
  An \textbf{instruction set architecture (ISA)} is the set of instructions supported by a
  computers. There are multiple (all incompatible) ISA's and they usually come in families.
\end{tcolorbox}

ISA's usually come with privilaged and standard instruction sets.

\begin{tcolorbox}[title=Definition: Platform]
  A \textbf{platform} is the combination of hardware and software that provide an environment for
  running applications.
\end{tcolorbox}

Common platforms include: Windows, [Mac, i]OS, Linux.

\begin{tcolorbox}[title=Definition: Binary Distribution Model]
  The \textbf{binary distribution model} is the paradigm of distributing software in compiled or
  machine code in the form of executables.
\end{tcolorbox}

The binary distribution model is good for performance and security, but lacks in flexibility and is
dependent on the platform you compile it for.

\begin{tcolorbox}[title=Definition: Portability]
  \textbf{Portability} refers to the ability to be adapted to different platforms with minimal
  modifications to the source code.
\end{tcolorbox}

Portability is important if you're an OS designer because you want to maximize the number of people
using your product $\implies$ your OS should run on many ISA's and make minimal assumptions about
specific hardware.





% \begin{tcolorbox}[colback=red!5!white,colframe=red!75!red,title=WIP]
%   \subsection{Virtualization}
%   \begin{tcolorbox}[colback=black!5!white,colframe=black!75!black,title=\textit{4) The Abstraction: The Process}]
%     \begin{tcolorbox}[title=Definition: Process]
%       A \textbf{process} is an abstraction of a running program. It has an API 
%     \end{tcolorbox}
%   \end{tcolorbox}
% \end{tcolorbox}



\section{Resource Types}
This section covers three types of OS resources: serially reusable, partitionable, and
sharable.

\begin{tcolorbox}[title=Definition: Graceful Transition]
  A \textbf{graceful transitions} refers to the process of transferring control between two jobs
  such that there are no resource conflicts. 
\end{tcolorbox}

A graceful transition maintains system stability, data integrity and therefore cleanly releases
resources. They typically ensure that users leave resources in a clean state; i.e. each
subsequent user finds the resource in a ``like new'' condition.


\subsection{Serially Reusable}
\begin{tcolorbox}[title=Definition: Serially Reusable Resource]
  \textbf{Serially reusable resources} are resources that can be used by a single process at a time
  (sequentially) and are not designed to be shared in parallel.
\end{tcolorbox}

These resources require access control mechanisms to ensure that only one process can access them at
any given time. This control ensures a graceful transition between users and prevents conflicts or
data corruption that may arise from concurrent access.

\begin{tcolorbox}[colback=blue!5!white,colframe=black!75!blue,title=Example: Printing Process]
  Printers are a serially reusable resource: multiple job can use it but only a single job will be
  printed at a time. 
\end{tcolorbox}

\subsection{Partitionable}
\begin{tcolorbox}[title=Definition: Partitionable Resource]
  \textbf{Partitionable resources} can be divided up (or \textit{partitioned}) into smaller,
  disjoint\footnote{Disjoint: Independent of one another.} segments.  
\end{tcolorbox}

These resources require access control mechanisms to ensure that each segment is
\textit{contained}\footnote{Contained: Resources outside of a partition are not accessible.} and
\textit{private}\footnote{Private: External users cannot access the resources in your
  partition.}. Partitionable resources can be temporarily allocated (e.g. RAM, CPU \textit{time
  slice}, etc.) or permanently allocated (e.g. Disk
storage\footnote{Disk storage is permanently allocated until it isn't. You can use something like
  \texttt{fdisk} (in Linux) to modify partitions.}, database tables, etc.).

\begin{tcolorbox}[colback=blue!5!white,colframe=black!75!blue,title=Example: Memory Mania and Disk Division]
  Memory can be partitioned, allowing multiple unique processes to access their own allocated memory
  space independently.
  \tcblower
  Disk storage can be partitioned into separate logical volumes! This is commonly used to dual-boot
  different operating systems. Recently, M1(/2\textit{ish}) Apple products can now run Linux on
  bare metal (still in beta !) via Asahi Linux!
\end{tcolorbox}

Graceful transitions are still necessary in partitionable resources! Partitionable resources that
aren't permanently allocated need to clean up after themselves.


\subsection{Shareable}

\begin{tcolorbox}[title=Definition: Shareable Resource]
  \textbf{Shareable resources} are usable by multiple \textit{concurrent} clients. They need not
  ``wait'' for access nor do they ``own'' a particular subset of a given shared resource. 
\end{tcolorbox}

These resources require access control mechanisms to ensure that the shareable resource is used in a
controlled and secured manner.

\begin{tcolorbox}[colback=blue!5!white,colframe=black!75!blue,title=Example: Cloud Crazy] 
  The cloud (e.g. Google Drive, Oracle Cloud, etc.) is a powerful shared resource! It enables
  multiple concurrent users to access shared folders and files, facilitating simultaneous editing
  and collaboration.
\end{tcolorbox}

Graceful transitions typically are not necessary since a shareable resource generally doesn't change
state \textit{or} doesn't require any clean up. In the example above, while the cloud files change
state, there is no cleaning up to do, so a graceful transition is not necessary (what's clean
doesn't need cleaning).





\section{Services}
The OS provides services in a multitude of ways. This section will introduce and explain how
services are provided throughout the software stack.


\subsection{Subroutines}
\begin{tcolorbox}[title=Definition: Subroutine]
  A \textbf{subroutine} in the context of operating systems is a small, self-contained and reusable
  portion of code that performs a specific function.
\end{tcolorbox}

Subroutines are usually called directly, and operate like normal code (stack manipulation), and are
typically seen in higher layers of the OS stack. They are fast, but usually cannot use the
privileged instruction set. Furthermore, they are usually not language agnostic. The most common way
to implement these subroutines are libraries!

\subsection{Libraries}
One way the OS provides services to users is via libraries. Standard utility functions such as
\texttt{malloc} can be found in libraries (in this case, \texttt{stdlib.h}). So what exactly is a
library?

\begin{tcolorbox}[title=Definition: Library]
  A \textbf{library} is a collection of code modules that encapsulate common operations, algorithms,
  and functionality. 
\end{tcolorbox}

\begin{tcolorbox}[colback=violet!5!white,colframe=violet,title=Abstraction: Libraries] 
  Most systems are equipped with a wide range of standard libraries, which are designed to be
  reused. These libraries encapsulate complexity and provide an additional layer of abstraction,
  simplifying problem-solving. 
\end{tcolorbox}

\begin{tcolorbox}[colback=blue!5!white,colframe=black!75!blue,title=Example: DSA Doozy] 
  In DSA, you likely had to implement different types of data structures (linear, hierarchical,
  graphical, etc.) and algorithms (search, divide/conquer, dynamic programming). Imagine your
  surprise when you find out most of these data structures and algorithms have already been written
  (and probably perform better than your implementation, no offense).
\end{tcolorbox}

\subsubsection{Bind Time}
The choice of library bind time depends on multiple factors that include (but are not limited to):
performance requirements, deployment and distribution considerations, and dependency
management.

\begin{tcolorbox}[title=Definition: Static]
  \textbf{Static} libraries are precompiled code modules that link directly to the executable at
  compile time. They allow for efficient standalone executables, but they result in larger file
  sizes and require recompilation if the library is updated.  
\end{tcolorbox}
One easy example of a static library is \texttt{libc}, or the \texttt{C} standard library! It
encapsulates a myriad of commonly used operations, algorithms, and functionality when programming in
\texttt{C} like everyone's favorite \texttt{malloc()}. 

\begin{tcolorbox}[title=Definition: Shared/Dynamic]
  \textbf{Shared/Dynamically Linked} libraries are separate files from the load modules that can
  be loaded and shared by multiple concurrent processes. They are loaded and linked to the
  executable during runtime. 
\end{tcolorbox}

One thing to note about shared libraries is that they cannot define or include global data
storage. Moreover, called routines must be known at compile time since the fetching of the code is
the only thing that is delayed until runtime. 


\subsection{System Calls}
\begin{tcolorbox}[title=Definition: System Call]
  A \textbf{system call} is when users request functionalities from the operating system that are a
  part of the privileged instruction set.
\end{tcolorbox}

System calls allow for the use of the privileged instruction set and interprocess communication, so
why don't we just make everything a system call? System calls are \textit{slow}\footnote{System
  calls are between 100 and 1,000 times slower than standard subroutine calls!}. Thus, we typically
like to reserve system calls for operations that \textit{require} the privileged instruction set.

\begin{tcolorbox}[colback=blue!5!white,colframe=black!75!blue,title=Example: System Call Stress] 
  System calls sound like a big deal, but you have already been introduced to them! Some include:
  \begin{enumerate}[label=\textit{(\roman*)}]
  \item File I/O: Reading from or writing to files on a disk require system calls since they require
    privileged instructions.
  \item Memory management: Though functions like \texttt{malloc()} itself isn't a system call, it is
    implemented by calling system calls!
  \item Process management: Only the kernel can \textit{directly} create/destroy processes and
    ensure process privacy and containment.
  \item Interprocess communication: Mainly for security reasons, communication between processes
    require privileged instructions.
  \end{enumerate}
\end{tcolorbox}

Most of the time, everything related to a given system call is dealt with in the kernel. However,
there are instances when the kernel will outsource tasks via direct calls to
\textit{untrusted}\footnote{Untrusted: Not guaranteed to be secure.}
code, waiting for a response, then returning to the calling process. 


\subsubsection{Trusted Code}
Not all trusted code must be inside the kernel! If code doesn't \textit{need} to access kernel data
structures or execute privileged instructions, they might sit outside of the kernel layer. 

\begin{tcolorbox}[title=Definition: Trust]
  \textbf{Trusted} code is guaranteed to be secure and will perform correctly. That is, it is safe
  for the operating system to run it.
\end{tcolorbox}


\begin{tcolorbox}[colback=blue!5!white,colframe=black!75!blue,title=Example: Lazy Login] 
  A login manager/application is a great example of a program that is trusted but doesn't sit inside
  the kernel. When you login, the kernel will outsource the job to the login application!
\end{tcolorbox}


\subsection{Messages}
Another way of service delivery is via messages that are exchanged with a server via system
calls.

\begin{tcolorbox}[colback=blue!5!white,colframe=black!75!blue,title=Advantages and Disadvantages, sidebyside] 
  Messages allow users to send and receive requests from anywhere! They are also highly scalable and
  can be implemeneted in user-mode code.
  \tcblower
  Messages are \textit{slow}\footnote{Messages are between 1,000 and 100,000 times slower than
    subroutine calls!} and are limited to operate on process resources.
\end{tcolorbox}



\subsection{Middleware}
Middleware refers to software components that are essential for a particular application or service
platform but do not sit inside the OS. They bridge the gap between the application and underlying
OS, providing additional functionalities and services.

\begin{tcolorbox}[colback=blue!5!white,colframe=black!75!blue,title=Example: Middleware Madness] 
  Some examples of middleware include database systems, web servers (like Apache and Nginx),
  distributed computing platforms (like Hadoop and Zookeeper), and cloud computing platforms like
  OpenStack.
\end{tcolorbox}

We prefer middleware over implementing such functionalities directly in the kernel because kernel
code is expensive and risky since kernel-level issues can impact the stability of the entire system!
Instead, middlware is typically developed in user mode, making it easier to build, test, and
debug\footnote{If the middleware crashes, it can be restarted independently of the entire system,
  minimizing its impact on the overall OS stability.}. Moreover, it is more portable, meaning it can
be used across different operating systems without modification!





\section{Interfaces}
How do processes communicate with the OS? Interfaces! There are two main types: API and ABI.

\begin{tcolorbox}[colback=violet!5!white,colframe=violet,title=Abstraction: Interfaces] 
  Interfacess introduce a layer of abstraction, allowing programmers to focus on \textit{what} they need
  without worrying about \textit{how} it's implemented! 
\end{tcolorbox}


\subsection{Application Programming Interface}
\begin{tcolorbox}[title=Definition: Application Programming Interface]
  The \textbf{application programming interface (API)} provides a standardized set of rules and
  policies (at the source code level) that govern how different software components can communicate
  with each other.
\end{tcolorbox}

API's are the basis for software portability, allowing a program to be compiled for a particular
architecture or OS. That is, programmers can recompile for different targets without changing the source
code, provided that the API is consistent. To do this, we link our program with OS-specific
libraries that implement the funcitonality specified by the API.

Thus, when the program is compiled and linked using an API-compliant system, the binary executable
will be compatible\footnote{An API-compliant program will compile and run on any system that
  supports the same API.} with any other API-compliant system! Well-defined API's allow us to create
interoperable applications and libraries that are platform/system independent, promoting software
portability, reusability, and simplicity when building complex systems!


\subsection{Application Binary Interface}
\begin{tcolorbox}[title=Definition: Application Binary Interface]
  The \textbf{application binary interface (ABI)} defines the low-level binary interface that allows
  compiled programs to interact with the underlying system and hardware.
\end{tcolorbox}

ABI's govern how DLL's are structured and how they interact with programs at a binary level. But
how? ABI's define how data is represented in memory and passed between functions and across
different modules! This includes details like register usage, linkage conventions, parameter passing
conventions, and stack layout. They also connect the API to the specific hardware, translating
source-level instructions to actual machine level instructions.

Once a program is compiled using an ABI-compliant system, it can run unmodified (i.e. without
recompilation) on any other system with the same ABI! This ensure that a single binary can service 
all ABI-compliant systems. Hence, they are usually intended for end-users and software deployment.


\subsection{Corollary: Libraries}
Libraries are accessed through API's! The API provides source-level definitions for how to access
the library, and is readily portable between systems. While DLL's are also accessed via an API, the
loading mechanism is specified by the ABI.


\subsection{Best Practices for Interoperability}
Standalone programs are useless! All useful programs use system calls, library routines, operate on
external files, exchange messages, etc. That is, they all utilize OS services! Thus, if the
interface changes, these programs will fail. Thus, API requirements are frozen (finalized) at
compile time. This means:

\begin{enumerate}[label=\textit{(\roman*)}]
\item Execution platforms must support the interfaces.
\item All partners/services must support the interface protocols.
\item The API must be backwards compatible
\end{enumerate}

That is, API's need to be \textit{stable} in order to support interoperability! API's need to be
rigorously specified and standardized\footnote{Standard body: Most big projects (like Linux) have
  standard bodies that manage the interface definitions so as to maintain stability!}. Thus, the
developers that use the API are encouraged to be compliant with the API specifications to ensure
that their program will survive updates.

\begin{tcolorbox}[colback=blue!5!white,colframe=black!75!blue,title=Example: New Version New Problems] 
  Suppose you are writing an application for an OS running on version 0.6.8, and being the genius
  programmer you are, find an exploit that goes around the OS API to make your app run
  faster. Everything runs fine until version 0.6.9. Confused, you find that the developers hate you
  in particular and decided to patch the exploit you used. Having learned your lesson, you have to
  rewrite that entire feature, being compliant with the API.
\end{tcolorbox}

Interoperability requires both parties to honor their side of the contract: Standard bodies must
keep the interface stable, while developers must be compliant with the API if they want their
products to survive new updates.


\subsection{Aside: Side Effects}

\begin{tcolorbox}[title=Definition: Side Effect]
  A \textbf{side effect} is occurs when an action on one object has
  \textit{non-trivial}\footnote{Non-trivial: Effects that are not included in the interface
    specifications.} consequences. 
\end{tcolorbox}

Side effects are inevitable, but are not the end of the world! They usually happen due to shared
state between independent modules and functions. Thus, developers should ignore side effects and
continue being compliant with the interface as they \textit{should} be patched. In general, try to
avoid exploiting side effects since they are not guaranteed to be there or maintained! 





\section{Abstraction}
Recall that we like abstractions in Computer Science. Life is easy for high level programmers if
they work with a simple abstraction. The OS is responsible for creating managing, and exporting such
abstractions.

\begin{tcolorbox}[colback=blue!5!white,colframe=black!75!blue,title=Example: Hardware Hiding] 
  Hardware is fast, but complex and limited, so using it \textit{correctly} can be extremely
  challenging. Thus, hardware is commonly seen as a building block rather than a solution. We
  provide abstractions to encapsulate implementation details (like error handling and performance
  optimization) and eliminate behavior that is irrelevant to the user. Thus, abstractions make
  it more convenient to work with the hardware!
\end{tcolorbox}

The OS provides some core abstractions that our computational model relies on: memory, processor,
and communication abstractions.


\subsection{Memory Abstractions}
Memory abstractions provide a consistent way to interact with various data storage resources,
simplifying the process for users. However, there are some complicating factors that come with
abstracting memory.


\subsubsection{Complications}
The operating system managing these abstractions doesn't have abstract devices having arbitrary
properties. Instead, it handles physical devices that may have inconvenient properties. Therefore,
the primary goal of OS abstraction is to create an abstract device with desirable properties derived
from the physical device that lacks them. 

\subsubsection*{Memory Lifetime}
\begin{tcolorbox}[title=Definition: Persistent and Transient Memory]
  \textbf{Persistent memory} retains data even when power is turned off (long term memory). Examples
  of non-volatile storage include hard drives and solid state drives.
  \tcblower
  \textbf{Transient memory} loses its data when power is turned off (short term memory). An example of
  volatile storage is RAM.
\end{tcolorbox}

Managing data in both types of memory presents different challenges and considerations when
designing a complex system.

\begin{tcolorbox}[colback=blue!5!white,colframe=black!75!blue,title=Example: File Finding] 
  When you run a program, all of the variables local to the program are stored in transient memory,
  or RAM. However, suppose you write to a file \texttt{foo} in your program. \texttt{foo} is stored
  in persistent memory! This means that weeks later, if another program wants to access foo
  (e.g. \texttt{cat foo}), the contents you wrote into \texttt{foo} will still be there.
\end{tcolorbox}

\subsubsection*{Size}
There can be a discrepancy between the size of memory operations that the user wants to work with
and the size that the physical memory can handle. Thus, being able to manage data manipulation
efficiently, especially when data sizes differ, is very important!

\begin{tcolorbox}[colback=blue!5!white,colframe=black!75!blue,title=Example: Caught in 4k] 
  Hardware usually processes data at the word level\footnote{Word sizes are typically 32 or 64 bits
    depending on the architecture}. However, when writing a block of data to flash memory, we
  typically move data in 4k chunks. Therefore, when reading from or writing to memory, we must
  ensure that data is moved in the appropriate word size. 
\end{tcolorbox}


\subsubsection*{Latency}
\begin{tcolorbox}[title=Definition: Persistent and Transient Memory]
  \textbf{Latency} (in the context of memory) refers to the time it takes for a process to read from
  memory.
\end{tcolorbox}

Note that the latency reading from RAM and from disk are two very different times which lead to
varying performance gains depending on which one you optimize for.


\subsubsection*{Implementation Variety}
The same memory abstraction might be implemented using various physical devices. This leads to
varying performance depending on which device imlements the abstraction.

\begin{tcolorbox}[colback=blue!5!white,colframe=black!75!blue,title=Example: Caught in 4k] 
  Storage devices like hard disks, solid-state drives, and optical drives can all be used to
  implement file storage, but the performance differences vary between the three. (SSD $>$
  HD $>$ optical).
\end{tcolorbox}


\subsection{Interpreters}

\begin{tcolorbox}[title=Definition: Persistent and Transient Memory]
  An \textbf{interpreter} is the module (abstract or physical) that executes commands and ``gets
  things done''.
\end{tcolorbox}

\begin{tcolorbox}[colback=violet!5!white,colframe=violet,title=Abstraction: Interpreters] 
  At the physical level, we have the CPU. Directly working with the CPU is not easy, so the OS
  provides a higher level intepreter!
\end{tcolorbox}

An interpreter has several basic components: 
\begin{enumerate}[label=\textit{(\roman*)}]
\item Instruction Reference: Tells the interpreter which instruction to execute next.
\item Repertoire: The set of features that the interpreter supports.
\item Environment Reference: Describes the current state on which the next instruction should be
  executed.
\item Interrupts: Situations in which the instruction reference pointer is overridden.
\end{enumerate}

\begin{tcolorbox}[colback=blue!5!white,colframe=black!75!blue,title=Example: Processing Processes] 
  The process that we interface with is an example of an interpreter. The OS maintains the
  \textit{instruction reference} (a program counter for a given process). Its source code specifies
  its \textit{repertoire}, and its stack, heap, and register contents are its
  \textit{environment}. The OS manages all three of these components. Another thing to note is that
  no other interpreters should be able to access the process' resources; i.e. the interpreter should
  be private.
\end{tcolorbox}

\subsubsection*{Aside: Implementation}
Implementing the process abstraction in the OS is relatively straightforward when dealing with only
one process, but in reality, that is seldom the case. When dealing with multiple processes, we have
to consider that:
\begin{enumerate}[label=\textit{(\roman*)}]
\item The OS has limited physical memory to hold environment information.
\item There are usually only one set of registers (or one per core).
\item The process shares the CPU (or core) with other processes!
\end{enumerate}
To address these issues, we need:
\begin{enumerate}[label=\textit{(\roman*)}]
\item A \textit{scheduler} to share the CPU among multiple processes.
\item Better \textit{memory management} hardware and software to create the illusion that
  each process has full access to RAM (when in reality, they don't).
\item Access control mechanisms for other memory abstractions to keep our machine secure.
\end{enumerate}

\subsection{Communications}

\begin{tcolorbox}[title=Definition: Communication Link]
  A \textbf{communication link} allows interpreters to talk to each other (on the same or different machines).
\end{tcolorbox}

\begin{tcolorbox}[colback=violet!5!white,colframe=violet,title=Abstraction: Communication Links] 
  A communication link at the physical level consists of memory and cables. However, at more
  abstract levels, we have networks and interprocess communication mechanisms.
\end{tcolorbox}

Communication links are distinct from memory abstractions for a couple of reasons:
\begin{enumerate}[label=\textit{(\roman*)}]
\item Factors such as network congestion, distance, and hardware limits contribute to variations in
  speed, latency, and bandwidth. On the other hand, memory access offers more predictability and
  consistent performance.  

\item Communication links are often asynchronous\footnote{Asynchronous: Data can be sent and
    received independently of each other. Timing of communication is not guaranteed to be
    coordinated.}, introducing additional complexity compared to synchronous memory access. 

\item The receiver in communication links may be reactive, meaning they only perform an operation
  because the sender initiated it. In contrast, data is usually immediately available when requested
  via memory access. 
\end{enumerate}


\subsubsection*{Aside: Implementation}
If both ends of the communication link are on the same machine, it's trivial: use memory for
transferring data! Copy the message from the sender's memory into the receiver's memory \textit{or}
transfer \textit{control}\footnote{Transferring control: Change who owns the memory segment!} of the memory
containing the message from the sender to the receiver. To implement communication links across
machines, we have to consider the following:

\begin{enumerate}[label=\textit{(\roman*)}]
\item We need to optimize the cost of copying data.
\item Memory management can become very tricky (especially when manipulating ownership!).
\item We need to include complex network protocols into the OS itself. This raises new security
  concerns that the OS might need to address.
\item We need to be able to deal with message loss, retransmission, etc.
\end{enumerate}


\subsection{Generalizing Abstractions: Introduction to Federation Frameworks}
Rather than applications dealing with varied resources, we can make many different things
\textit{appear}\footnote{We want to \textit{abstract} away the implementation details!} the same by
using a unifying model! Usually, these unifying models involve a federation framework.

\begin{tcolorbox}[colback=blue!5!white,colframe=black!75!blue,title=Example: Computer Communism] 
  A Portable Document Format, or PDF, is the unifying model for printed output. If we want to print
  something to a printer, as long as the document is in the PDF format, it will know how to print it!
  \tcblower
  SCSI, SATA, and SAS are standard ways to interface with hard disks and other storage devices (CD,
  SSD, etc.).
\end{tcolorbox}

\begin{tcolorbox}[title=Definition: Federation Framework]
  A \textbf{federation framework} is a structural design that enables similar (but different)
  entities to be treated uniformly by creating a single \textit{interface}\footnote{The
    \textit{implementation} that supports the interface is specified by the particular entities.}
  that all entities must adhere to. 
\end{tcolorbox}

Note that a unifying model need not be the model with the ``lowest common
denominator''\footnote{Lowest common denominator: The set of features \textit{all} entities have in
  common.}. Rather, the model can include ``optional features'' which are implemented in a standard
way. Why? Some devices may have features that others of the same class do not. Thus, these
``optional features'' allow us to create a highly modular federation framework while maintaining a
common unifying model.

\begin{tcolorbox}[colback=blue!5!white,colframe=black!75!blue,title=Example: Pretty Printing] 
  Suppose you are building a federation framework for printers. Some printers can only print
  single-sided while others can print double-sided. So, a possible federation framework 
  could require that all devices that classify as printers \textit{must} be able to print \textit{at
    least} single-sided, with the \textit{optional feature} of double-sided printing. Extending this
  idea, we can add more optional features like color printing, DPI settings, etc.
\end{tcolorbox}

Unfortunately, there may be instances where a particular device may have features that cannot be
exploited through a common model. This is the tradeoff we make for a uniform model. There have been
arguments both for and against being able to handle such features in a federation framework.


\subsection{Layering Abstractions}
It is very common practice to create increasingly complex services by \textit{layering}
abstractions.

\begin{tcolorbox}[colback=blue!5!white,colframe=black!75!blue,title=Example: Abstract Abstract Abstract!] 
  A generic file system is an abstraction layer over a particular file system (1). A particular file
  system layers on top of an abstract disk (2). This abstract disk layers on a real disk (3). Here,
  a generic file system is implemented with 3 layers of abstraction! This hierarchical structure
  simplifies development and enhances system scalability.
\end{tcolorbox}

Layering allows for modularity, easy development of multiple services on multiple layers, and
flexibility in supporting various underlying services. Abstractions hide complex implementation
details, promoting structured and independent design.

Unfortunately, layers in a system often introduce performance penalties due to the additional
indirection they bring. Moving between layers can be costly as it typically involves changing data
structures and representations, and may require extra instructions. Moreover, layers may not be
entirely independent of one another; for example, lower layers can impose limitations on what upper
layers can achieve.

\begin{tcolorbox}[colback=blue!5!white,colframe=black!75!blue,title=Example: Packages Play Hide n Seek] 
  An abstract network link may hide causes of packet loss, since the lower layer that this
  abstraction is built off of may hide certain implementation details that are relevant to these issues.
\end{tcolorbox}

The OS offers numerous abstractions, catering to diverse needs and use cases. Selecting
the most suitable abstractions is crucial for achieving optimal results. It involves
understanding the trade-offs between higher-level and lower-level abstractions to ensure efficient
utilization of system resources and effective application development.





\section{The Process}
\definitionBegin{Process and State}
A \textbf{process} is a type of interpreter that executes an instance of a
\textit{program}\footnote{A \textbf{program} is a set of instructions that defines a particular
  application.}.
\tcblower
A \textbf{state} is a mode or condition of being, representable by a set of bits.
\definitionEnd

When you begin executing a program, it becomes a process. There may be multiple instances of the
same program running simultaneously on the same computer. Typically in these cases, each running
instance is a separate process. 

\abstractionBegin{Abstraction: Processes}
Processes are a type of interpreter, an abstraction we covered in the previous section. We can
think of it as a virtual private computer.
\abstractionEnd

A process is an \textit{object}\footnote{Object: NOT the OOP object.}, characterized by its
state and its operations. All persistent objects have state, distinguishing them from other objects
and characterizing the object's current condition. OS's objects' state is mostly managed by the OS
itself and not by the user code. Thus, we must ask the OS to access or alter the state of an OS object.

\exampleBegin{Example: Priority Process}
The OS maintains information about the current priority of each process in the system. This subset
of \textit{state} determines its position in the scheduling queue.
\exampleEnd


\subsection{Process Address Space}
\definitionBegin{Definition: Process Address Space}
The \textbf{process address space} is the set of addresses visible to the process. This address
space is \textit{private}\footnote{Private: Inaccessible by outside processes.} to the process.
\definitionEnd

The process' address space consists of all memory locations accessible by the process. Invalid
addresses are those outside its address space, and as such, the process cannot request access to
them. Modern operating systems give the illusion that \textit{every} process' address space can (but
often don't) include \textit{all} of memory.


\subsubsection{Layout}
The process address space typically consists of different segments:
\begin{enumerate}[label=\textit{(\roman*)}]
\item Shared Code: Contains the executable code of the program. We do not do self-modifying code in
  modern computer systems. Thus, this shared code is static while the process is running, meaning
  they are read/executable only. So, subsequent instances of a program will be accessing the one
  stored in RAM since it's a \textit{shared resource}.
\item Shared Libraries: Like shared code, shared libraries are a \textit{shared resource} that are
  stored somewhere in RAM. Thus, multiple processes can access these shared libraries concurrently.
\item Private Data: Stores global and static variables used by the program. Since private data is
  read/write, they are \textit{not} a shared resource, and thus is private to a particular instance
  of a process.
\item Private Stack: Like private data, the private stack is private to a particular instance of a process.
\end{enumerate}
All of these must sit somewhere in RAM, but different type of memory elements have different
requirements (e.g. \textit{shared} coded is read/execute, \textit{private} stack is
read/write). 

\exampleBegin{Linux Layout}
Each operating system puts these process memory segments in different places, but here's how Linux
does it! Code segments are statically sized and are put at the beginning (e.g. 0x00000000). The data
segment (and heap) is placed after the code segment and grows upward. The stack is placed at the
very end (e.g. 0xFFFFFFFF) and grows downward. It is crucial that the data segment and stack are
\textbf{not} allowed to meet! 
\exampleEnd


\subsubsection{Code Segment}
\definitionBegin{Load Module}
The \textbf{load module} is the output of a linkage editor, where all external references have been
resolved and object modules have been combined into a single executable.
\definitionEnd

The process starts by creating a load module. To make instructions executable, we need to load the
code into RAM, as we can't directly run instructions from the disk. Next, we read the code from the
load module and copy it into a specific \textit{code segment}\footnote{Code segment: A segment we
  establish in the process' address space to accommodate the code.} within the process's address
space. This allows the CPU to fetch and execute instructions from the memory while the program
runs. Since the code is static (read/execute only), we can
share it among multiple processes, which helps reduce unnecessary duplication of code. 


\subsubsection{Data Segment}
Data also needs to be initialized within the address space of a process. This requires the creation
and mapping of a process data segment into the process' address space. The initial contents of the
data segment are copied from the load module. In particular, the BSS\footnote{BSS: Block Started by
  Symbol} segments are initialized to all zeroes. Data segments are read/write (and thus private to
the instance of the process). The program can grow or shrink this segment (via the \texttt{sbrk}
syscall).


\subsubsection{Stack Segment}
\definitionBegin{Stack Frame}
A \textbf{stack frame} serves as storage for procedure local variables, invocation parameters, and
save/restore registers.
\definitionEnd

Modern programming languages are stack-based. Thus, each procedure call allocates a new stack
frame, and once it is completed, the corresponding stack frame is popped off of the stack, freeing
any memory that was allocated for it. Modern CPU's have built-in stack support. Thus, the stack must
be preserved as part of the process state to ensure proper execution and continuity during a
process' lifetime.

The size of the stack in a program depends on its activities, such as the amount of local storage
used by each routine. It grows larger as calls nest more deeply (since each procedure call allocates
a new stack frame!), and once these calls return, their stack frames can be recycled for future use.


\subsubsection*{Who Manages The Stack?}
The operating system is responsible for managing the process' stack segment! It is created alongside
the data segment when the program is loaded into memory.

Different operating systems implement stack management differently Some allocate a fixed-size stack
at the program's load time, while others dynamically extend the stack as the program needs more
space.

Across all operating systems, stack segments are usually only read/write for security reasons. This
prevents any unintended execution of code in the stack (e.g. buffer overflows) and ensures that it
is used exclusively for storing data and variables.

Stack segments are process private, meaning each process has its own unique stack. This isolation
ensures that processes cannot interfere with each other's stacks, which is crucial for maintaining
system stability and security.



\end{document}

% Local Variables:
% mode: latex
% TeX-master: t
% End:
